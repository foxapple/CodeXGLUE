"""A CaseRecorder and CaseIterator that store the cases in a CSV file.
"""

import csv, datetime, glob, os, shutil, time
import cStringIO, StringIO

# pylint: disable=E0611,F0401
from openmdao.main.interfaces import implements, ICaseRecorder, ICaseIterator
from openmdao.main.case import Case, flatten_obj

from openmdao.lib.casehandlers.util import driver_map


class CSVCaseIterator(object):
    """An iterator that returns :class:`Case` objects from a passed-in iterator
    of cases. This can be useful for runtime-generated cases from an
    optimizer, etc.

    Current limitations:
        Quote character in the input CSV file should be ``'`` or ``"``. Other
        choices don't seem to get identified by csv.Sniffer.

        All string data must be contained inside of quotes. This includes
        field headers.
    """

    implements(ICaseIterator)

    def __init__(self, filename='cases.csv', headers=None):
        self.data = []
        self.headers = headers
        self.timestamp_field = None
        self._need_fieldnames = True

        #Open Input file
        self._filename = None
        self.filename = filename

    @property
    def filename(self):
        """Get the name of the CSV file."""
        return self._filename

    @filename.setter
    def filename(self, name):
        """Set the CSV file name."""
        self._filename = name

        with open(self.filename, 'r') as infile:
            # Sniff out the dialect
            #infile.seek(1)
            dialect = csv.Sniffer().sniff(infile.readline())
            infile.seek(0)
            reader = csv.reader(infile, dialect, quoting=csv.QUOTE_NONNUMERIC)

            self.data = []
            for row in reader:
                self.data.append(row)

            if self.headers is None:
                self._need_fieldnames = True
            else:
                self._need_fieldnames = False
                if 'timestamp' in self.headers.values():
                    for key, value in self.headers.iteritems():
                        if value == 'timestamp':
                            self.timestamp_field = key
                            del self.headers[key]
                            break

    def __iter__(self):
        return self._next_case()

    def _next_case(self):
        """ Generator which returns Cases one at a time. """
        uuid = parent_uuid = msg = ""
        uuid_field = parent_uuid_field = msg_field = None
        if self.headers is None:
            input_fields = {}
        else:
            input_fields = self.headers
        output_fields = {}

        for row in self.data:

            # Get fieldnames from file
            if self._need_fieldnames:

                # OpenMDAO-style CSV file
                if '/INPUTS' in row:
                    input_fields, output_fields = self._parse_fieldnames(row)

                    self.timestamp_field = 1
                    uuid_field = row.index('/METADATA') + 1
                    parent_uuid_field = uuid_field + 1
                    msg_field = uuid_field + 2

                # Read headers from file
                elif self.headers is None:
                    for i, field in enumerate(row):
                        if field == 'timestamp':
                            self.timestamp_field = i
                        else:
                            input_fields[i] = field

                self._need_fieldnames = False
                continue

            if uuid_field is not None:
                uuid = row[uuid_field]
                parent_uuid = row[parent_uuid_field]
                msg = row[msg_field]

            inputs = []
            for i, field in input_fields.iteritems():

                # Convert bools from string back into bools
                # Note, only really need this for inputs.
                if row[i] in ['True', 'False']:
                    row[i] = bool(row[i])

                inputs.append((field, row[i]))

            outputs = []
            for i, field in output_fields.iteritems():
                outputs.append((field, row[i]))

            exc = None if not msg else Exception(msg)

            yield Case(inputs=inputs, outputs=outputs, exc=exc,
                       parent_uuid=parent_uuid)

        self._need_fieldnames = True

    def _parse_fieldnames(self, row):
        """Parse our input and output fieldname dictionaries."""
        input_fields = {}
        output_fields = {}

        # This file was generated by a CSVCaseRecorder
        if '/INPUTS' in row:

            in_start = row.index('/INPUTS') + 1
            out_start = row.index('/OUTPUTS') + 1
            out_end = row.index('/METADATA')

            if in_start < out_start-1:
                for i in range(in_start, out_start-1):
                    input_fields[i] = row[i]

            if out_start < len(row)-1:
                for i in range(out_start, out_end):
                    output_fields[i] = row[i]

        # This file was generated externally
        else:
            pass

        return input_fields, output_fields

class CSVCaseRecorder(object):
    """Stores cases in a csv file. Defaults to cases.csv."""

    implements(ICaseRecorder)

    def __init__(self, filename='cases.csv', append=False, delimiter=',',
                 quotechar='"'):

        self.delimiter = delimiter
        self.quotechar = quotechar
        self.append = append
        self.outfile = None
        self.csv_writer = None
        self.num_backups = 5
        self._header_size = 0
        self._cfg_map = {}

        #Open output file
        self._write_headers = False
        self._filename = None
        self.filename = filename

    def __getstate__(self):
        """ Returns state as a dict. """
        state = self.__dict__.copy()
        # If already open, restored recorder will append to reopened file.
        state['append'] = self.append or (self.outfile is not None)
        state['outfile'] = None
        state['csv_writer'] = None
        return state

    def __setstate__(self, state):
        """ Restore state from `state`. """
        self.__dict__.update(state)

    @property
    def filename(self):
        """Get the name of the CSV file."""
        return self._filename

    @filename.setter
    def filename(self, name):
        """Set the CSV file name."""
        self._filename = name

    def startup(self):
        """ Opens the CSV file for recording."""
        if self.append:
            self.outfile = open(self.filename, 'a')
        else:
            self.outfile = open(self.filename, 'w')

            # Whenever we start a new CSV file, we need to insert a line
            # of headers. These won't be available until the first
            # case is passed to self.record.
            self._write_headers = True
            self._cfg_map = {}

        self.csv_writer = csv.writer(self.outfile, delimiter=self.delimiter,
                                     quotechar=self.quotechar,
                                     quoting=csv.QUOTE_NONNUMERIC)

    def register(self, driver, inputs, outputs):
        """Register names for later record call from `driver`."""
        self._cfg_map[driver] = driver_map(driver, inputs, outputs)

    def record_constants(self, constants):
        """Record constant data - currently ignored."""
        pass

    def record(self, driver, inputs, outputs, exc, case_uuid, parent_uuid):
        """Store the case in a csv file. The format for a line of data
        follows:

        Field 1      - timestamp
        Field 2      - [Empty]
        Field 3      - Input 1
        ...
        Field i+2    - Input i
        Field i+3    - [Empty]
        Field i+4    - Output 1
        ...
        Field i+j+4  - Output j
        Field i+j+5  - [Empty]
        Field i+j+6  - uuid
        Field i+j+7  - parent_uuid
        Field i+j+8  - msg
        """
        sorted_input_keys = []
        sorted_input_values = []
        sorted_output_keys = []
        sorted_output_values = []

        in_cfg, out_cfg = self._cfg_map[driver]
        input_keys = []
        input_values = []
        for name, obj in zip(in_cfg, inputs):
            for key, value in flatten_obj(name, obj):
                input_keys.append(key)
                input_values.append(value)

        output_keys = []
        output_values = []
        for name, obj in zip(out_cfg, outputs):
            for key, value in flatten_obj(name, obj):
                output_keys.append(key)
                output_values.append(value)

        # This should not be necessary, however python's csv writer
        # is not writing boolean variables correctly as strings.

        for index, item in enumerate(input_values):
            if isinstance(item, bool):
                input_values[index] = str(item)

        for index, item in enumerate(output_values):
            if isinstance(item, bool):
                output_values[index] = str(item)

        # Sort the columns alphabetically.

        if len(input_keys) > 0:
            sorted_input_keys, sorted_input_values = \
                (list(item) for item in zip(*sorted(zip(input_keys,
                                                        input_values))))
        if len(output_keys) > 0:
            sorted_output_keys, sorted_output_values = \
                (list(item) for item in zip(*sorted(zip(output_keys,
                                                        output_values))))
        if self.outfile is None:
            raise RuntimeError('Attempt to record on closed recorder')

        if self._write_headers or self._header_size == 0:
            headers = ['timestamp', '/INPUTS']
            headers.extend(sorted_input_keys)
            headers.append('/OUTPUTS')
            headers.extend(sorted_output_keys)
            headers.extend(['/METADATA', 'uuid', 'parent_uuid', 'msg'])

            self.csv_writer.writerow(headers)
            self._write_headers = False
            self._header_size = len(headers)

        msg = '' if exc is None else str(exc)

        data = [time.time()]
        data.append('')
        data.extend(sorted_input_values)
        data.append('')
        data.extend(sorted_output_values)
        data.extend(['', case_uuid, parent_uuid, msg])

        if self._header_size != len(data):
            raise RuntimeError("number of data points (%d) doesn't match header"
                               " size (%d) in CSV recorder"
                               % (len(data), self._header_size))

        self.csv_writer.writerow(data)

    def close(self):
        """Closes the file."""
        if self.csv_writer is not None:
            if not isinstance(self.outfile,
                              (StringIO.StringIO, cStringIO.OutputType)):
                # Closing a StringIO deletes its contents.
                self.outfile.close()
            self.outfile = None
            self.csv_writer = None

        # Save off a backup copy if requested.
        if self.num_backups > 0:
            timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')

            parts = self.filename.split('.')
            if len(parts) > 1:
                name = ''.join(parts[:-1])
                extension = parts[-1]
                backup_name = '%s_%s.%s' % (name, timestamp, extension)
                globname = name
            else:
                backup_name = '%s_%s' % (self.filename, timestamp)
                globname = self.filename

            if os.path.isfile(self.filename):
                shutil.copyfile(self.filename, backup_name)

            # Clean up old backups if we exceed our max
            backups = glob.glob(globname + '_*')
            if len(backups) > self.num_backups:
                sortbackups = sorted(backups)
                for item in sortbackups[:len(backups) - self.num_backups]:
                    os.remove(item)

    def get_iterator(self):
        '''Return CSVCaseIterator that points to our current file.'''

        # I think we can safely close the oufile if someone is
        # requesting the iterator
        self.close()

        return CSVCaseIterator(self.filename)
